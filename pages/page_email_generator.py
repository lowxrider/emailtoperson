# pages/page_email_generator.py

import streamlit as st
from openai import OpenAI
from utils.db import get_connection
import pandas as pd

def get_clients(conn):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç–æ–≤ –∏–∑ –ë–î –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame."""
    return pd.read_sql_query(
        "SELECT * FROM customers;",
        conn
    )

def get_prompts(conn):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–º–ø—Ç—ã –∏–∑ –ë–î –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame."""
    return pd.read_sql_query(
        "SELECT id, description, prompt FROM library_prompts;",
        conn
    )

def main():
    st.title("‚úâÔ∏è –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä Email-—Ä–∞—Å—Å—ã–ª–æ–∫")

    # 1) –ü—Ä–æ–≤–µ—Ä–∫–∞ API-–∫–ª—é—á–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI
    api_key = st.session_state.get("openai_api_key", "").strip()
    if not api_key:
        st.warning("–£–∫–∞–∂–∏—Ç–µ OpenAI API Key –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö LLM")
        return
    client = OpenAI(api_key=api_key)

    # 2) –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    model       = st.session_state.get("model",      "gpt-3.5-turbo")
    temperature = st.session_state.get("temperature", 0.7)
    top_p       = st.session_state.get("top_p",       0.9)
    max_tokens  = st.session_state.get("max_tokens",  256)

    # 3) –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    conn = get_connection()
    clients_df = get_clients(conn)
    prompts_df = get_prompts(conn)

    # 4) –í—ã–±–æ—Ä –∫–ª–∏–µ–Ω—Ç–æ–≤ (–º—É–ª—å—Ç–∏–≤—ã–±–æ—Ä)
    client_options = {
        f"{row.first_name} {row.last_name} (ID {row.id})": row.id
        for row in clients_df.itertuples()
    }
    selected = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞—Å—Å—ã–ª–∫–∏",
        options=list(client_options.keys())
    )
    selected_ids = [client_options[k] for k in selected]

    # 5) –í—ã–±–æ—Ä –ø—Ä–æ–º–ø—Ç–∞
    prompt_map = {
        row.description: row.prompt
        for row in prompts_df.itertuples()
    }
    prompt_desc = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ —à–∞–±–ª–æ–Ω (–ø—Ä–æ–º–ø—Ç)",
        options=list(prompt_map.keys())
    )
    template = prompt_map[prompt_desc]

    # 6) –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
    if st.button("üöÄ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–º—É –∏ —Ç–µ–∫—Å—Ç –ø–∏—Å—å–º–∞"):
        if not selected_ids:
            st.error("–ù—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞.")
        else:
            output = []
            for cid in selected_ids:
                # –±–µ—Ä—ë–º –¥–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–∞ –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å
                client_row = clients_df[clients_df.id == cid].iloc[0].to_dict()
                # —Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç, –ø–æ–¥—Å—Ç–∞–≤–ª—è—è –ø–æ–ª—è –∫–ª–∏–µ–Ω—Ç–∞
                filled = template.format(**client_row)

                # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ LLM
                with st.spinner(f"–ì–µ–Ω–µ—Ä–∏—Ä—É—é –¥–ª—è {client_row['first_name']} {client_row['last_name']}..."):
                    resp = client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content":
                                "–í—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥, –ø–∏—à—É—â–∏–π –ø—Ä–æ–¥–∞—é—â–∏–µ email-—Ä–∞—Å—Å—ã–ª–∫–∏."},
                            {"role": "user", "content":
                                f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Ç–µ–º—É –∏ —Ç–µ–ª–æ –ø–∏—Å—å–º–∞ –ø–æ —Å–ª–µ–¥—É—é—â–µ–º—É –∑–∞–ø—Ä–æ—Å—É:\n\n{filled}"}
                        ],
                        temperature=temperature,
                        top_p=top_p,
                        max_tokens=max_tokens
                    )
                ans = resp.choices[0].message.content.strip()
                output.append(f"---\n–ö–ª–∏–µ–Ω—Ç: {client_row['first_name']} {client_row['last_name']} (ID {cid})\n\n{ans}")

            # 7) –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            st.text_area(
                "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏",
                value="\n\n".join(output),
                height=400
            )

if __name__ == "__main__":
    main()
