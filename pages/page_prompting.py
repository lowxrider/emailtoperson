# pages/page_prompting.py

import streamlit as st
import datetime
from openai import OpenAI
from utils.db import get_connection

def main():
    st.title("ü§ñ –ß–∞—Ç —Å LLM")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ API-–∫–ª—é—á –∑–∞–¥–∞–Ω
    api_key = st.session_state.get("openai_api_key", "")
    if not api_key:
        st.warning("–£–∫–∞–∂–∏—Ç–µ OpenAI API Key –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö LLM")
        return

    # –°–æ–∑–¥–∞—ë–º –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
    client = OpenAI(api_key=api_key)
    model       = st.session_state.get("model", "gpt-3.5-turbo")
    temperature = st.session_state.get("temperature", 0.7)
    top_p       = st.session_state.get("top_p", 0.9)
    max_tokens  = st.session_state.get("max_tokens", 256)

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ë–î
    conn = get_connection()
    conn.execute("""
        CREATE TABLE IF NOT EXISTS last_prompts (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            prompt TEXT,
            response TEXT,
            timestamp TEXT
        );
    """)
    conn.execute("""
        CREATE TABLE IF NOT EXISTS library_prompts (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            description TEXT NOT NULL,
            prompt TEXT NOT NULL
        );
    """)
    conn.commit()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", "content": "–í—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ email-—Ä–∞—Å—Å—ã–ª–æ–∫."}
        ]

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    # –í–≤–æ–¥ –Ω–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    user_input = st.chat_input("–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
    if user_input:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        st.session_state.messages.append({"role": "user", "content": user_input})
        st.chat_message("user").write(user_input)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ LLM
        with st.spinner("–ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç..."):
            resp = client.chat.completions.create(
                model=model,
                messages=st.session_state.messages,
                temperature=temperature,
                top_p=top_p,
                max_tokens=max_tokens
            )
        assistant_msg = resp.choices[0].message.content

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        st.session_state.messages.append({"role": "assistant", "content": assistant_msg})
        st.chat_message("assistant").write(assistant_msg)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤
        conn.execute(
            "INSERT INTO last_prompts (prompt, response, timestamp) VALUES (?, ?, ?);",
            (user_input, assistant_msg, datetime.datetime.now().isoformat())
        )
        conn.commit()

        # –ö–Ω–æ–ø–∫–∞ –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ (user_input) –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫—É –ø—Ä–æ–º–ø—Ç–æ–≤
        if st.button("‚ûï –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫—É", key="save_user_prompt"):
            conn.execute(
                "INSERT INTO library_prompts (description, prompt) VALUES (?, ?);",
                ("", user_input),
            )
            conn.commit()
            st.success("–ó–∞–ø—Ä–æ—Å –¥–æ–±–∞–≤–ª–µ–Ω –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫—É –ø—Ä–æ–º–ø—Ç–æ–≤")

    # (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –∫–Ω–æ–ø–∫—É –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ —Å—Ç—Ä–∞–Ω–∏—Ü–µ library_prompts
    if st.button("–ü–µ—Ä–µ–π—Ç–∏ –∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –ø—Ä–æ–º–ø—Ç–æ–≤"):
        # –µ—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ session_state –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
        st.session_state["_page"] = "page_library_prompts"
        st.rerun()


if __name__ == "__main__":
    main()
